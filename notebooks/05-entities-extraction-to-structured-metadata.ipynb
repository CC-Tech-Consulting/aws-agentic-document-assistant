{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f560f9c1-2672-4a55-9cc8-0603c67198d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 05 - Structured metadata extraction for analytical question answering\n",
    "\n",
    "In this notebook we will be using the output of the `question-answering-using-rag.ipynb` notebook to generate structured data containing specified entities extracted from each of the documents. We will then use this structured data to answer questions.\n",
    "\n",
    "Notebook overview:\n",
    "1. Define the embedding model to initialize the vectorstore created in `04-question-answering-using-rag.ipynb` (faiss_vector_store).\n",
    "2. Define the LLM model that will be used to extract the entities.\n",
    "3. Define the entities to be extracted.\n",
    "4. Extract the entities.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- To be able to extract relevant entities from the provided documents, the LLM needs to have a clear definition of what it is trying to extract. For example, if you want to extract the profit of a company from one of its financial reports, then asking the question \"What is the profit?\" might not be specific enough since the report can contain the profits of other companies. It may be important for your documents in S3 to contain relevant metadata that can be used in the queries to make the entities more specific.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4400ce0-5209-4b8b-af2e-de73a5ba2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f663c22-e990-43e0-bd65-a1d3425e078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm_client = boto3.client(\"ssm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7cb1f8-3c81-443d-933a-5af99f66d298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_region_parameter = \"/AgenticLLMAssistant/bedrock_region\"\n",
    "bedrock_endpoint_parameter = \"/AgenticLLMAssistant/bedrock_endpoint\"\n",
    "s3_bucket_name_parameter = \"/AgenticLLMAssistant/AgentDataBucketParameter\"\n",
    "\n",
    "BEDROCK_REGION = ssm_client.get_parameter(Name=bedrock_region_parameter)\n",
    "BEDROCK_REGION = BEDROCK_REGION[\"Parameter\"][\"Value\"]\n",
    "\n",
    "S3_BUCKET_NAME = ssm_client.get_parameter(Name=s3_bucket_name_parameter)\n",
    "S3_BUCKET_NAME = S3_BUCKET_NAME[\"Parameter\"][\"Value\"]\n",
    "\n",
    "BEDROCK_REGION, S3_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58535b5f-5fb9-403d-9fb4-485e0eb36b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_MODEL_ID = \"anthropic.claude-v1\"\n",
    "LLM_MODEL_ID = \"anthropic.claude-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc0029-22ff-4b47-9146-54d26f2a2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = Config(\n",
    "    region_name=BEDROCK_REGION, retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    ")\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", config=retry_config)\n",
    "bedrock = boto3.client(\"bedrock\", config=retry_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed130f7-ca2f-4129-8f77-a8df6bbd064e",
   "metadata": {},
   "source": [
    "First get all of the documents that were used to create the vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9bdae-0924-405c-8f52-8f056b8c7d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import load_list_from_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d473e1d-5600-4853-b6a2-7081d8c5e25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_key = \"documents_processed.json\"\n",
    "documents_processed = load_list_from_s3(S3_BUCKET_NAME, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e76caa-9dea-43fa-8284-28f360c7442e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(documents_processed), len(documents_processed[0][\"pages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4b4a-7c16-4686-bdfa-4eea70dca78c",
   "metadata": {},
   "source": [
    "## Define the embedding model to embed the queries.\n",
    "\n",
    "Make sure to use the same embedding model that was used to create the embeddings for the documents.\n",
    "In this notebooks, we will continue to use the Titan embedding model from Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6cc93-d0e5-48a0-b0b4-ba3aa1ff804e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "# Define an embedding model to generate embeddings\n",
    "embedding_model_id = \"amazon.titan-embed-text-v1\"\n",
    "embedding_model = BedrockEmbeddings(model_id=embedding_model_id, client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88aabd-86a5-4873-a40f-d3999312fcfb",
   "metadata": {},
   "source": [
    "#### Initialize the vectorstore using the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f201ea1-3c67-4df5-a113-4d6839118de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "faiss = FAISS.load_local(\"faiss_vector_store\", embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cde7db-6ec8-4beb-be5f-3f9584fe25ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment the following to show the stored chunks in the vector store.\n",
    "# faiss.docstore._dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77138e-3f8c-45bd-8997-d724023a614d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the generation model, which does the extraction\n",
    "\n",
    "For the generation model you are free to choose which model you would like to use, in this notebook we use Amazon Titan embedding model available through Amazon Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c55f9-c91f-4b96-8b81-4d665882f78c",
   "metadata": {},
   "source": [
    "Define an Amazon Bedrock generation model\n",
    "\n",
    "- If you did not use Amazon Bedrock in the `question-answering-using-rag.ipynb` notebook, please go to that notebook first and follow the installation steps mentioned there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5500986-cf83-4856-9412-ae2f3cb9be92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock as LangchainBedrock\n",
    "\n",
    "# Define a generation model to generate text\n",
    "claude_llm = LangchainBedrock(\n",
    "    model_id=LLM_MODEL_ID,\n",
    "    client=bedrock_runtime,\n",
    "    model_kwargs={\"max_tokens_to_sample\": 1024, \"temperature\": 0.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6b83e-1ce4-4a06-be16-1f5087eb7c62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the entities to be extracted\n",
    "For the sake of simplicity we are considering entities that can be described using a `description` and a `type`.<br>\n",
    "You can easily generate a description for your entities using an LLM with the prompt \"Can you give a description of what '{entity}' means regarding a company, in a maximum of 2 sentences\".\n",
    "\n",
    "The `rag_query` represents the query that will be used to find relevant context to extract the entity from. This query can contain the available metadata about the document you are trying to extract the entity from. In our case, we have `company` and `year` as available metadata for each document.<br>\n",
    "It is wise to experiment with the `rag_query` to improve the returned context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f6326-a421-4e86-a25c-f511bf55a003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_list = {\n",
    "    \"revenue\": {\n",
    "        \"description\": \"Total income from goods sold or services provided in {company} in {year} exactly as defined in the document within <document></document> XML tags.\",\n",
    "        \"rag_query\": \"What is the total revenue of {company} in {year}.\",\n",
    "    },\n",
    "    \"risks\": {\n",
    "        \"description\": \"Summary of risks impacting {company} in {year} as defined in the document within <document></document> XML tags.\",\n",
    "        \"rag_query\": \"What are the main risks for {company} in {year}.\",\n",
    "    },\n",
    "    \"human_capital\": {\n",
    "        \"description\": \"The total number of employees in {company} in {year} exactly as defined in the document within <document></document> XML tags.\",\n",
    "        \"rag_query\": \"What is the total number of employees in {company} in {year}.\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d7222-7482-4d18-89f4-c746ba6cc2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method that returns all tables present on the page of the provided chunk.\n",
    "def add_tables(chunk):\n",
    "    # The company and year the chunk corresponds to\n",
    "    chunk_company = chunk.metadata[\"company\"]\n",
    "    chunk_year = chunk.metadata[\"year\"]\n",
    "\n",
    "    # The document and page that the chunk came from\n",
    "    doc = [\n",
    "        document\n",
    "        for document in documents_processed\n",
    "        if (\n",
    "            document[\"metadata\"][\"company\"] == chunk_company\n",
    "            and document[\"metadata\"][\"year\"] == chunk_year\n",
    "        )\n",
    "    ][0]\n",
    "    pages = doc[\"pages\"]\n",
    "    page = [\n",
    "        page\n",
    "        for page in pages\n",
    "        if (int(page[\"page\"]) == int(chunk.metadata[\"page_number\"]))\n",
    "    ][0]\n",
    "\n",
    "    # The tables (in markdown) that are present on the page that the chunk came from\n",
    "    tables = \"\"\n",
    "    for table_markdown in page[\"page_tables\"]:\n",
    "        tables += \"\\n\" + table_markdown\n",
    "    return chunk.page_content + \"\\n\" + tables.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7a55f-e880-497a-b5b8-03bcdb05d035",
   "metadata": {},
   "source": [
    "Use the following to experiment with the semantic search questions, and refine it to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa08407-c509-4f4f-9897-3d230f9f32c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment with different rag queries\n",
    "rag_query = \"What is the total revenue of {company} in {year}.\"\n",
    "\n",
    "# Referring to the Annual report of Amazon in 2021\n",
    "company = \"Amazon\"\n",
    "year = 2021\n",
    "\n",
    "# Find context relevant to the query\n",
    "for doc in faiss.similarity_search(\n",
    "    query=rag_query.format(\n",
    "        company=company,\n",
    "        year=year,\n",
    "    ),\n",
    "    k=1,\n",
    "    filter={\n",
    "        # \"document_s3_metadata\": {\"company\": company},\n",
    "        \"company\": company,\n",
    "        # \"year\": year\n",
    "    },\n",
    "    fetch_k=1000,\n",
    "):\n",
    "    # print(doc.metadata)\n",
    "    print(\"\\n\\n\")\n",
    "    print(add_tables(doc))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb51e7-1db1-4392-9eff-27e7e103bc53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the context for the LLM to extract entities\n",
    "For each combination of entity and document we retrieve relevant context to present to the generation model, which will use the context during extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd3774-fcd5-4f81-a54d-85c8b5eb03aa",
   "metadata": {},
   "source": [
    "Retrieve the chunks for each combination of document and entity and store them.\n",
    "\n",
    "To improve the relevance of the retrieved documents you could use the document metadata added during creation of the vector store. If your documents in S3 have any S3 metadata attached to them, you should be able to reference it here using `document['metadata']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458749f-26f8-4a67-92c4-eb8deca326fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_doc_and_entity_to_chuncks = {}\n",
    "\n",
    "for document in documents_processed:\n",
    "    print(\"-\" * 79)\n",
    "    print(document[\"source_location\"])\n",
    "    map_doc_and_entity_to_chuncks[document[\"source_location\"]] = {}\n",
    "\n",
    "    # Use the S3 metadata to provide the prompt with relevant information\n",
    "    company = document[\"metadata\"][\"company\"]\n",
    "    year = document[\"metadata\"][\"year\"]\n",
    "\n",
    "    print(f\"Executing entity search on doc: {document['source_location']}\")\n",
    "    for entity in entity_list.keys():\n",
    "        query = entity_list[entity][\"rag_query\"].format(\n",
    "            company=company,\n",
    "            year=year,\n",
    "        )\n",
    "        print(f\"Query: {query}\")\n",
    "\n",
    "        document_entity_retrieved_chunks = faiss.similarity_search(\n",
    "            query=query,\n",
    "            k=4,\n",
    "            filter={\n",
    "                \"document_source_location\": document[\"source_location\"],\n",
    "            },\n",
    "            fetch_k=200,\n",
    "        )\n",
    "\n",
    "        map_doc_and_entity_to_chuncks[document[\"source_location\"]][entity] = {\n",
    "            \"chunks\": document_entity_retrieved_chunks,\n",
    "            \"metadata\": {\n",
    "                \"company\": company,\n",
    "                \"year\": year,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd590038-6417-4e45-90f9-5225baad91fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the entities to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135eef9-bd5e-45c8-8e67-bcbf408b474a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d62f3-11f2-4f42-a473-3355e0f6c79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_list[\"revenue\"][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153e1c8-67a9-4fa8-b8b2-30e550fd3ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class RevenueEntity(BaseModel):\n",
    "    revenue: float = Field(\n",
    "        description=entity_list[\"revenue\"][\"description\"], default=None\n",
    "    )\n",
    "    revenue_reasoning: str = Field(\n",
    "        description=\"Put here the text from the document used to infer the value for the revenue field.\",\n",
    "        default=None,\n",
    "    )\n",
    "    revenue_unit: str = Field(\n",
    "        description=\"Put here the unit of the revenue using ISO alphabetic code.\",\n",
    "        default=None,\n",
    "    )\n",
    "    revenue_unit_reasoning: str = Field(\n",
    "        description=\"Put here the text from the document used to infer the value for the revenue_unit field.\",\n",
    "        default=None,\n",
    "    )\n",
    "\n",
    "\n",
    "class RisksEntity(BaseModel):\n",
    "    risks: str = Field(description=entity_list[\"risks\"][\"description\"], default=None)\n",
    "    risks_reasoning: str = Field(\n",
    "        description=\"Put here the text from the document used to infer the value for the risks field.\",\n",
    "        default=None,\n",
    "    )\n",
    "\n",
    "\n",
    "class HumanCapitalEntity(BaseModel):\n",
    "    human_capital: int = Field(\n",
    "        description=entity_list[\"human_capital\"][\"description\"], default=None\n",
    "    )\n",
    "    human_capital_reasoning: str = Field(\n",
    "        description=\"Put here the text from the document used to infer the value for the human_capital field.\",\n",
    "        default=None,\n",
    "    )\n",
    "\n",
    "\n",
    "entity_schema = {}\n",
    "entity_schema[\"revenue\"] = RevenueEntity\n",
    "entity_schema[\"risks\"] = RisksEntity\n",
    "entity_schema[\"human_capital\"] = HumanCapitalEntity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1fb45-3b21-47fa-a617-fec5dd59d587",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining example extractions for all entities\n",
    "\n",
    "To boost the performance of the extraction for some entities, we add an extraction example to leverage 1-shot in-context learning.\n",
    "The example is chosen based on the type of the entity that is being extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0ee1e-2d67-48eb-83d1-9763c1da1f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(entity_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a43e5-c59b-4c43-85e5-9b116966f531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "Example {index}: Given the information inside <schema> and <documents>, the correct output is inside <json> below:\n",
    "\n",
    "<schema>\n",
    "{serialized_json_schema}\n",
    "</schema>\n",
    "\n",
    "<documents>\n",
    "{document_excerpts}\n",
    "</documents>\n",
    "\n",
    "Correct output:\n",
    "<json>\n",
    "{json_output}\n",
    "</json>\n",
    "\"\"\"\n",
    "\n",
    "example_pairs = {\n",
    "    \"revenue\": [\n",
    "        {\n",
    "            \"document_excerpts\": \"Page 20 - After the 10% increase in the number of customers, the sales for Company Inc in 2019 was $513,983 million.\",\n",
    "            \"json_output\": json.dumps(\n",
    "                {\n",
    "                    \"revenue\": 324483000000,\n",
    "                    \"revenue_reasoning\": \"The sales for Company Inc in 2019 was $324,483 million.\",\n",
    "                    \"revenue_unit\": \"USD\",\n",
    "                    \"revenue_unit_reasoning\": \"The financial report is in US dollars as stated on page 20.\",\n",
    "                },\n",
    "                indent=1,\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    \"human_capital\": [\n",
    "        {\n",
    "            \"document_excerpts\": \"Despite the COVID-19 pandemic, In 2019, Company Inc employed 349,329 employees worldwide.\",\n",
    "            \"json_output\": json.dumps(\n",
    "                {\n",
    "                    \"human_capital\": 349329,\n",
    "                    \"human_capital_reasoning\": \"In 2019, Company Inc employed 349,329 employees worldwide.\",\n",
    "                },\n",
    "                indent=1,\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    \"risks\": [\n",
    "        {\n",
    "            \"document_excerpts\": \"\"\"Competition continues to intensify, including with the development of new business models and the entry of new and well-funded competitors, and as our competitors enter into business combinations or alliances and established companies in other market segments expand to become competitive with our business. In addition, new and enhanced technologies, including search, web and infrastructure computing services, digital content, etc.\"\"\",\n",
    "            \"json_output\": json.dumps(\n",
    "                {\n",
    "                    \"risks\": \"The main risks are: \\n* Competition from new entrants\\n* Increased competition because of new technologies, \",\n",
    "                    \"risks_reasoning\": \"Competition continues to intensify, including with the development of new business models and the entry of new and well-funded competitors. In addition, new and enhanced technologies continue to increase our competition.\",\n",
    "                },\n",
    "                indent=1,\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "few_shot_examples = {}\n",
    "\n",
    "for entity in entity_list.keys():\n",
    "    combined_examples = \"\\n\"\n",
    "    for idx, current_example in enumerate(example_pairs[entity]):\n",
    "        serialized_json_schema = json.dumps(\n",
    "            entity_schema[entity].model_json_schema(), indent=1\n",
    "        )\n",
    "        combined_examples += example_template.format(\n",
    "            index=idx + 1,\n",
    "            serialized_json_schema=serialized_json_schema,\n",
    "            document_excerpts=current_example[\"document_excerpts\"],\n",
    "            json_output=current_example[\"json_output\"],\n",
    "        )\n",
    "    few_shot_examples[entity] = combined_examples\n",
    "\n",
    "\n",
    "print(few_shot_examples[\"revenue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d5691d-2c4d-4266-87aa-a2d946e74884",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the prompt to extract the entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c13a3-2d2b-471c-8de1-b8d0603a6f09",
   "metadata": {},
   "source": [
    "The prompt for the extracting was inspired by the paper [PromptNER : Prompting For Named Entity Recognition](https://arxiv.org/abs/2305.15444).\n",
    "\n",
    "The main components are a clear goal, one or more examples, and chain-of-thought reasoning.\n",
    "\n",
    "We use Claude v2 model available through Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aba565-0386-41da-b38c-d6f926118ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "ENTITY_EXTRACTION_PROMPT_TEMPLATE = \"\"\"\\n\\nHuman: Extract the information described by the json schema inside the <schema></schema> XML tags from the documents inside <documents></documents> XML tags.\n",
    "Follow the rules inside the <rules></rules> XML tags during extraction:\n",
    "<rules>\n",
    "1. You must output a valid JSON.\n",
    "2. You must extract the value for each from the text inside <documents></documents>, and the value must match the description and type in JSON schema.\n",
    "3. Expand numbers into full digits format: example 1: 212,765,000,000 becomes 212765000000, example 2: $469.822 million becomes 469822000, example 3: 132,452 people becomes 132452.\n",
    "4. Don't use comma as thousands separator in the numbers you extract. For example 212,765 must be written as 212765.\n",
    "5. Consider the context inside <context></context> XML tags.\n",
    "6. If the document does not contain the value, put null.\n",
    "</rules>\n",
    "\n",
    "The JSON schema inside the <schema></schema> XML tags contains the information to extract:\n",
    "<schema>\n",
    "{serialized_json_schema}\n",
    "</schema>\n",
    "\n",
    "Extract information from the documents inside <documents></documents> XML tags below:\n",
    "<documents>\n",
    "{document_excerpts}\n",
    "</documents>\n",
    "\n",
    "Use the metadata inside the <context></context> XML tags when relevant to assist you during extraction:\n",
    "<context>\n",
    "The company is {company}.\n",
    "The year of the financial report is {year}.\n",
    "</context>\n",
    "\n",
    "Follow the extraction examples inside the <examples></examples> XML tags below:\n",
    "<examples>\n",
    "{few_shot_examples}\n",
    "</examples>\n",
    "\n",
    "Only write the JSON output inside <json></json> XML tags without further explanation.\n",
    "\n",
    "\\n\\nAssistant: <json>\\n\"\"\"\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=claude_llm,\n",
    "    prompt=PromptTemplate.from_template(ENTITY_EXTRACTION_PROMPT_TEMPLATE),\n",
    ")\n",
    "\n",
    "\n",
    "def get_extracted_entity(\n",
    "    entity, metadata, chunks, entity_schema, few_shot_examples_dict\n",
    "):\n",
    "    \"\"\"Prepare the prompt for entity extraction.\"\"\"\n",
    "    document_excerpts = \"\"\n",
    "    for chunk in chunks:\n",
    "        document_excerpts += \"\\n\".join(\n",
    "            [\n",
    "                f\"- Below Excerpt of page {chunk.metadata['original_page_number']:}\",\n",
    "                \"\\n\",\n",
    "                f\"{add_tables(chunk)}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # parser = PydanticOutputParser(pydantic_object=entity_schema[entity])\n",
    "    few_shot_examples = few_shot_examples_dict.get(entity, \"\")\n",
    "    serialized_json_schema = json.dumps(\n",
    "        entity_schema[entity].model_json_schema(), indent=1\n",
    "    )\n",
    "\n",
    "    prompt = ENTITY_EXTRACTION_PROMPT_TEMPLATE.format(\n",
    "        entity=entity,\n",
    "        metadata=metadata,\n",
    "        serialized_json_schema=serialized_json_schema,\n",
    "        company=metadata[\"company\"],\n",
    "        year=metadata[\"year\"],\n",
    "        document_excerpts=document_excerpts,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "    )\n",
    "\n",
    "    result = llm_chain.predict(\n",
    "        entity=entity,\n",
    "        metadata=metadata,\n",
    "        serialized_json_schema=serialized_json_schema,\n",
    "        company=metadata[\"company\"],\n",
    "        year=metadata[\"year\"],\n",
    "        document_excerpts=document_excerpts,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "    )\n",
    "\n",
    "    return result, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88834a9-1fca-41a8-bdec-92bff1821ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to save all the extracted items\n",
    "import json\n",
    "\n",
    "extracted_entities = []\n",
    "k = 2\n",
    "\n",
    "# Create a prompt for each combination of document and entity\n",
    "for document in list(map_doc_and_entity_to_chuncks.keys()):\n",
    "    # You could additionally use the metadata of documents defined in S3 to customize these prompts\n",
    "    # This metadata can also be found in the `documents_processed` variable under the key `metadata`.\n",
    "    document_name = document.split(\"/\")[-1]\n",
    "    # extracted_entities[document] = {}\n",
    "\n",
    "    for entity in entity_list.keys():\n",
    "        current_entity_result = {}\n",
    "        current_entity_result[\"entity_type\"] = entity\n",
    "        current_entity_result[\"source_doc\"] = document\n",
    "\n",
    "        print(\"-\" * 79)\n",
    "        print(f\"Starting extraction of {entity} from document {document_name}\")\n",
    "        try:\n",
    "            chunks = map_doc_and_entity_to_chuncks[document][entity][\"chunks\"]\n",
    "            if not chunks:\n",
    "                print(\n",
    "                    f\"WARNING: The input chunks are empty for {document} and {entity}. Skipping.\"\n",
    "                )\n",
    "                continue\n",
    "            metadata = map_doc_and_entity_to_chuncks[document][entity][\"metadata\"]\n",
    "            # extraction_example = entity_list[entity]['example']\n",
    "            # extraction_example = extraction_example,\n",
    "            current_entity_result.update(metadata)\n",
    "            result, prompt = get_extracted_entity(\n",
    "                entity=entity,\n",
    "                metadata=metadata,\n",
    "                chunks=chunks,\n",
    "                entity_schema=entity_schema,\n",
    "                few_shot_examples_dict=few_shot_examples,\n",
    "            )\n",
    "        # If the maximum context length was exceeded, try again with less context\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "\n",
    "        current_entity_result[\"result\"] = result\n",
    "        current_entity_result[\"prompt\"] = prompt\n",
    "        extracted_entities.append(current_entity_result)\n",
    "\n",
    "    print(f\"Finished extracting entities from document: {document}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e72c67-d19a-46c7-907b-f53517ebf68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for extraction in extracted_entities:\n",
    "    print(\"-\" * 79)\n",
    "    print(extraction.keys())\n",
    "    print(extraction[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e779076-07f5-438d-95bb-c1b20a91ea56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pased_entities = []\n",
    "\n",
    "for extraction in extracted_entities:\n",
    "    current_entity = {}\n",
    "    # current_entity[\"entity_type\"] = extraction[\"entity_type\"]\n",
    "    current_entity[\"source_doc\"] = extraction[\"source_doc\"]\n",
    "    current_entity[\"company\"] = extraction[\"company\"]\n",
    "    current_entity[\"year\"] = extraction[\"year\"]\n",
    "\n",
    "    print(\"-\" * 79)\n",
    "    result = extraction[\"result\"]\n",
    "\n",
    "    try:\n",
    "        parser = PydanticOutputParser(\n",
    "            pydantic_object=entity_schema[extraction[\"entity_type\"]]\n",
    "        )\n",
    "        # We already feed the Assistant the start of the output <json>\\n\n",
    "        # to ensure it abides to the output format. Therefore, it will generate\n",
    "        # starting from {.., so we add <json>\\n here to complete the XML tags.\n",
    "        result = \"<json>\\n\" + result\n",
    "        json_result = parser.parse(result).dict()\n",
    "        print(json_result)\n",
    "        current_entity.update(json_result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse output with error {e} for the following\")\n",
    "        print(result)\n",
    "\n",
    "    pased_entities.append(current_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02f88a-c879-455d-bdbf-a34028df306b",
   "metadata": {},
   "source": [
    "Inspect extraction result and extraction prompt to verify their structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e405093-b60c-4d63-a5fa-5e3e8543f973",
   "metadata": {},
   "source": [
    "#### Store the extracted entities in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0a85e-a3d7-4cb8-bc98-3272ff5b5e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pased_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe9ee4-39fd-49e6-8b5d-4af6008f7474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Group by company and year into defaultdict\n",
    "grouped = defaultdict(lambda: defaultdict(list))\n",
    "for d in pased_entities:\n",
    "    # del d[\"entity_type\"]\n",
    "    grouped[d[\"company\"]][d[\"year\"]].append(d)\n",
    "\n",
    "# Flatten into list of dicts for DataFrame\n",
    "results = []\n",
    "for comp, years in grouped.items():\n",
    "    for year, items in years.items():\n",
    "        result = {\"company\": comp, \"year\": year}\n",
    "        for item in items:\n",
    "            for k, v in item.items():\n",
    "                if k not in result:\n",
    "                    result[k] = v\n",
    "        results.append(result)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbc734-7123-4b4f-9068-e219e54de06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entities_df = pd.DataFrame(results)\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fab09-70ef-4723-8616-5eb66e4cb71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities_df.to_csv(\"extracted_entities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a66f4-d762-4623-b9eb-f9b4f103223d",
   "metadata": {},
   "source": [
    "## Upload structured metadata csv file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625f761-8c6a-4ea3-8a5d-c63db949ab81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp ./extracted_entities.csv s3://{S3_BUCKET_NAME}/structured_metadata/extracted_entities.csv"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
